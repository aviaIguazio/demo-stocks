{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape news and Analyse sentiments\n",
    "This notebook shows an example of scraping news articles linked to specific traded companies and utilizing our predeployed sentiment analysis model server to predict the sentiment of the author towards said companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "# if the nuclio-jupyter package is not installed run !pip install nuclio-jupyter\n",
    "import nuclio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio env -c V3IO_ACCESS_KEY=${V3IO_ACCESS_KEY}\n",
    "%nuclio env -c V3IO_USERNAME=${V3IO_USERNAME}\n",
    "%nuclio env -c V3IO_API=${V3IO_API}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd \n",
    "pip install beautifulsoup4\n",
    "pip install pandas\n",
    "pip install v3io_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio config spec.build.baseImage = \"python:3.6-jessie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import Request, urlopen\n",
    "import requests\n",
    "import pandas as pd\n",
    "import v3io_frames as v3f\n",
    "from unicodedata import normalize\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Change this to the endpoint provided at the end of execution of 00-deploy-sentiment-model.ipynb.\n",
    "ENDPOINT = 'http://192.168.224.185:32181/'\n",
    "sym_to_url={'GOOGL': 'google-inc', 'MSFT': 'microsoft-corp', 'AMZN': 'amazon-com-inc', 'AAPL': 'apple-computer-inc'}\n",
    "client = v3f.Client('framesd:8081', container='bigdata')\n",
    "\n",
    "def get_stock_news_page(stock_string):\n",
    "    request = Request('https://www.investing.com/equities/' + stock_string + '-news', headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    content = urlopen(request).read()\n",
    "    return bs(content, 'html.parser')\n",
    "\n",
    "def get_internal_article_links(page):\n",
    "    news = page.find_all('div', attrs={'class': 'mediumTitle1'})[1]\n",
    "    articles = news.find_all('article', attrs={'class': 'js-article-item articleItem'})\n",
    "    return ['https://www.investing.com' + a.find('a').attrs['href'] for a in articles]\n",
    "\n",
    "def get_article_page(article_link):\n",
    "    request = Request(article_link, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    content = urlopen(request).read()\n",
    "    return bs(content, 'html.parser')\n",
    "\n",
    "def clean_paragraph(paragraph):\n",
    "    paragraph = re.sub(r'\\(http\\S+', '', paragraph)\n",
    "    paragraph = re.sub(r'\\([A-Z]+:[A-Z]+\\)', '', paragraph)\n",
    "    paragraph = re.sub(r'[\\n\\t\\s\\']', ' ', paragraph)\n",
    "    return normalize('NFKD', paragraph)    \n",
    "\n",
    "def extract_text(article_page):\n",
    "    text_tag = article_page.find('div', attrs={'class': 'WYSIWYG articlePage'})\n",
    "    paragraphs = text_tag.find_all('p')\n",
    "    text = '\\n'.join([clean_paragraph(p.get_text()) for p in paragraphs[:-1]])\n",
    "    return text\n",
    "\n",
    "def get_publish_time(article_page):\n",
    "    details = article_page.find('meta', attrs={'itemprop': 'datePublished'})\n",
    "    publish_date = details.get_attribute_list('content')[0]\n",
    "    return str(datetime.strptime(publish_date, '%Y-%m-%d'))\n",
    "\n",
    "def get_score(paragraph_scores):\n",
    "    return sum([score - 1 for score in paragraph_scores]) / len(paragraph_scores)  \n",
    "\n",
    "def get_article_scores(articles, endpoint):\n",
    "    scores = [] \n",
    "    for i, article in enumerate(articles):\n",
    "        print(f'getting score for article {i + 1}\\\\{len(articles)}')\n",
    "        event_data = {'instances': article.split('\\n')}\n",
    "        resp = requests.put(endpoint+'/bert_classifier_v1/predict', json=json.dumps(event_data))\n",
    "        scores.append(get_score(json.loads(resp.text)))\n",
    "    return scores\n",
    "    \n",
    "def handler(context, handler):\n",
    "    \n",
    "    syms = []\n",
    "    contents = []\n",
    "    links = []\n",
    "    times = []\n",
    "    sentiments = []\n",
    "    \n",
    "    for sym, url_string in sym_to_url.items():\n",
    "        news_page = get_stock_news_page(url_string)\n",
    "        article_links = get_internal_article_links(news_page)\n",
    "        article_pages = [get_article_page(link) for link in article_links]\n",
    "        articles = [extract_text(article_page) for article_page in article_pages]\n",
    "        curr_sentiments = get_article_scores(articles, ENDPOINT)\n",
    "        curr_times = [get_publish_time(article_page) for article_page in article_pages]\n",
    "        \n",
    "        sentiments += curr_sentiments\n",
    "        times += curr_times\n",
    "        for article, link in zip(articles, article_links):\n",
    "            syms.append(sym)\n",
    "            contents.append(article)\n",
    "            links.append(link)\n",
    "    \n",
    "    \n",
    "    for i in range(len(contents)):\n",
    "        record = {\n",
    "            'content': contents[i],\n",
    "            'time': times[i],\n",
    "            'symbol': syms[i],\n",
    "            'link': links[i],\n",
    "            'sentiment': sentiments[i]\n",
    "        }\n",
    "        \n",
    "        client.execute('stream', 'stock_stream', 'put', args={'data': json.dumps(record)})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuclio_sdk import Event\n",
    "\n",
    "event = Event()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting score for article 1\\6\n",
      "getting score for article 2\\6\n",
      "getting score for article 3\\6\n",
      "getting score for article 4\\6\n",
      "getting score for article 5\\6\n",
      "getting score for article 6\\6\n",
      "getting score for article 1\\8\n",
      "getting score for article 2\\8\n",
      "getting score for article 3\\8\n",
      "getting score for article 4\\8\n",
      "getting score for article 5\\8\n",
      "getting score for article 6\\8\n",
      "getting score for article 7\\8\n",
      "getting score for article 8\\8\n",
      "getting score for article 1\\7\n",
      "getting score for article 2\\7\n",
      "getting score for article 3\\7\n",
      "getting score for article 4\\7\n",
      "getting score for article 5\\7\n",
      "getting score for article 6\\7\n",
      "getting score for article 7\\7\n",
      "getting score for article 1\\6\n",
      "getting score for article 2\\6\n",
      "getting score for article 3\\6\n",
      "getting score for article 4\\6\n",
      "getting score for article 5\\6\n",
      "getting score for article 6\\6\n"
     ]
    }
   ],
   "source": [
    "handler(context, event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy as Serverless Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nuclio] 2020-08-06 09:22:23,007 (info) Build complete\n",
      "[nuclio] 2020-08-06 09:22:29,080 (info) Function deploy complete\n",
      "[nuclio] 2020-08-06 09:22:29,087 done updating read-news, function address: 192.168.224.185:32355\n",
      "%nuclio: function deployed\n"
     ]
    }
   ],
   "source": [
    "%nuclio deploy -p stocks -n read-news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
